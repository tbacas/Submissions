{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with Neural Nets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a procedure for building a neural network to recognize handwritten digits.  The data is from Kaggle, and you will submit your results to Kaggle to test how well you did!\n",
    "\n",
    "1. Load the training data (`train.csv`) from Kaggle\n",
    "2. Setup X and y (feature matrix and target vector)\n",
    "3. Split X and y into train and test subsets.\n",
    "4. Preprocess your data\n",
    "\n",
    "   - When dealing with image data, you need to normalize your `X` by dividing each value by the max value of a pixel (255).\n",
    "   - Since this is a multiclass classification problem, keras needs `y` to be a one-hot encoded matrix\n",
    "   \n",
    "5. Create your network.\n",
    "\n",
    "   - Remember that for multi-class classification you need a softamx activation function on the output layer.\n",
    "   - You may want to consider using regularization or dropout to improve performance.\n",
    "   \n",
    "6. Trian your network.\n",
    "7. If you are unhappy with your model performance, try to tighten up your model by adding hidden layers, adding hidden layer units, chaning the activation functions on the hidden layers, etc.\n",
    "8. Load in Kaggle's `test.csv`\n",
    "9. Create your predictions (these should be numbers in the range 0-9).\n",
    "10. Save your predictions and submit them to Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For this lab, you should complete the above sequence of steps for _at least_ two of the three \"configurations\":\n",
    "\n",
    "1. Using a `tensorflow` network\n",
    "2. Using a `keras` \"sequential\" network\n",
    "3. Using a `keras` convolutional network\n",
    "4. Using a `tensorflow` convolutional network (we did _not_ cover this in class!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tbaca\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\tbaca\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/train.csv')\n",
    "submit = pd.read_csv('./Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('label', axis = 1)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 18s 436us/step - loss: 0.2701 - acc: 0.9190\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 17s 410us/step - loss: 0.1076 - acc: 0.9680\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 17s 411us/step - loss: 0.0779 - acc: 0.9762\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 19s 455us/step - loss: 0.0579 - acc: 0.9825\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 20s 471us/step - loss: 0.0477 - acc: 0.9846\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_units = X_train.shape[1]\n",
    "hidden_units = input_units\n",
    "\n",
    "model.add(Dense(hidden_units, input_dim=input_units, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "adam = Adam(lr=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics =['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, \n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeqNNpreds = model.predict(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X = tf.placeholder(dtype=tf.float32,shape = (None, X_train.shape[1]),name = 'X')\n",
    "y = tf.placeholder(dtype = tf.float32, shape = (None), name = 'y')\n",
    "\n",
    "hidden1 = tf.layers.dense(X,units = X_train.shape[1], name = 'hidden1', activation = tf.nn.relu)\n",
    "hidden2 = tf.layers.dense(X,units = 200, name = 'hidden2', activation = tf.nn.relu)\n",
    "hidden3 = tf.layers.dense(X,units = 100, name = 'hidden3', activation = tf.nn.relu)\n",
    "hidden4 = tf.layers.dense(X,units = 50, name = 'hidden4', activation = tf.nn.relu)\n",
    "hidden5 = tf.layers.dense(X,units = 25, name = 'hidden5', activation = tf.nn.relu)\n",
    "\n",
    "y_hat = tf.layers.dense(hidden1, units=y_train.shape[1], activation=None)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(y, y_hat)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 1.9172049 1.9177629\n",
      "epoch 11 0.5067511 0.5058806\n",
      "epoch 21 0.33770096 0.3378381\n",
      "epoch 31 0.27300838 0.2782908\n",
      "epoch 41 0.2319678 0.2422182\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_err = []\n",
    "train_err = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        sess.run(training_op,\n",
    "                 feed_dict={X:X_train, y:y_train})\n",
    "        \n",
    "        train_loss = sess.run(loss, feed_dict={X:X_train, y:y_train})\n",
    "        test_loss = sess.run(loss, feed_dict={X:X_test, y:y_test})\n",
    "        test_err.append(test_loss)\n",
    "        train_err.append(train_loss)\n",
    "        if epoch % 10 == 0:\n",
    "            print('epoch', epoch+1, train_loss, test_loss)\n",
    "            \n",
    "    saver.save(sess, './iris.ckpt')\n",
    "        \n",
    "    pred = sess.run(y_hat, feed_dict={X:submit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_preds = np.empty(pred.shape[0], dtype=np.int32)\n",
    "for i,clas in enumerate(map(np.argmax, pred)):\n",
    "    class_preds[i] = clas\n",
    "    \n",
    "class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEMPPREDS = pd.DataFrame(class_preds)\n",
    "TEMPPREDS.index = np.arange(1, len(TEMPPREDS)+1)\n",
    "TEMPPREDS.reset_index(inplace = True)\n",
    "TEMPPREDS = TEMPPREDS.rename({'index':'ImageId', TEMPPREDS.columns[1]:'Label'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPPREDS.to_csv('TFNNpreds.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDS = SeqNNpreds.argmax(axis=-1)\n",
    "predcsv = pd.DataFrame(PREDS)\n",
    "predcsv.index = np.arange(1, len(predcsv)+1)\n",
    "predcsv.reset_index(inplace = True)\n",
    "predcsv = predcsv.rename({'index':'ImageId', predcsv.columns[1]:'Label'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predcsv.to_csv('SeqNNpreds1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Scores: SeqNNpreds = .97114\n",
    "              TFNNpreds = .93242\n",
    "              \n",
    "Note terrible accuracy scores but also not close enough to beat any of the other kaggle competitors.  Further development and I could probably achieve that 100% accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
