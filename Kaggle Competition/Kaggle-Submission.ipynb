{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "submit = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection + Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My initial assumption for starting the modeling process was to start with a few features and work up in complexity until I found a balance that yielded the best score.  This started by selecting a couple features that had a strong correlation to SalePrice.  Later, I added more and more features to the model which ended up returning my best score, or lowest RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice          1.000000\n",
       "Overall Qual       0.800207\n",
       "Gr Liv Area        0.697038\n",
       "Garage Area        0.649897\n",
       "Garage Cars        0.647781\n",
       "Total Bsmt SF      0.629303\n",
       "1st Flr SF         0.618486\n",
       "Year Built         0.571849\n",
       "Year Remod/Add     0.550370\n",
       "Full Bath          0.537969\n",
       "TotRms AbvGrd      0.504014\n",
       "Mas Vnr Area       0.503579\n",
       "Fireplaces         0.471093\n",
       "BsmtFin SF 1       0.423856\n",
       "Lot Frontage       0.341842\n",
       "Open Porch SF      0.333476\n",
       "Wood Deck SF       0.326490\n",
       "Lot Area           0.296566\n",
       "Bsmt Full Bath     0.283332\n",
       "Half Bath          0.283001\n",
       "2nd Flr SF         0.248452\n",
       "Bsmt Unf SF        0.190861\n",
       "Bedroom AbvGr      0.137067\n",
       "Screen Porch       0.134581\n",
       "3Ssn Porch         0.048732\n",
       "Mo Sold            0.032735\n",
       "Pool Area          0.023106\n",
       "BsmtFin SF 2       0.016432\n",
       "Misc Val          -0.007375\n",
       "Yr Sold           -0.015203\n",
       "Low Qual Fin SF   -0.041594\n",
       "Bsmt Half Bath    -0.045290\n",
       "Id                -0.051398\n",
       "MS SubClass       -0.087335\n",
       "Overall Cond      -0.097019\n",
       "Kitchen AbvGr     -0.125444\n",
       "Enclosed Porch    -0.135656\n",
       "PID               -0.255052\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corrwith(df['SalePrice']).sort_values(ascending = False)\n",
    "#General idea of which columns correlated strongly with SalePrice\n",
    "\n",
    "##features = ['Year Built','Year Remod/Add','Gr Liv Area'\n",
    "         ##,'Total Bsmt SF','Garage Area','1st Flr SF', 'Full Bath','Fireplaces','TotRms AbvGrd']\n",
    "\n",
    "##sns.heatmap(df[features].corr())\n",
    "\n",
    "#Model 1 correlations between predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we some code directly form my model one where in I selected a variety of numerical features that correlated with SalePriece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning had presented itself as the most important aspect for producing a good score.  There were several values that lacked proper data (presumably the standard for data scientists) that I needed to fill or replace to run in my model.  I found out later that this was not the right practice and when discussing with class mates I found that the proper method to handle these missing values was to either drop them entirely or replace them with a more telling value such as mean or median.  That being said, I will defend my actions for choosing zeros and none for the data.\n",
    "\n",
    "I found that many of the circumstances in which data was missing was likely due to a feature not being on a house.  I often confirmed this by finding the matching values of other identifiers.  Example being, garage-finish and garage sqft.  I found that if a house had no information regarding their garage/basement of other feature I would presume there was nothing there at all.  Thus, filling categorical values with None (later dummying them) and numericals with 0 would yield the proper data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Garage Finish'].fillna('None', inplace = True)\n",
    "df['Garage Qual'].fillna('None', inplace = True)\n",
    "df['Garage Finish'].fillna('None', inplace = True)\n",
    "df['Garage Type'].fillna('None', inplace = True)\n",
    "df['Garage Cond'].fillna('None', inplace = True)\n",
    "df['Bsmt Exposure'].fillna('None', inplace = True)\n",
    "df['BsmtFin Type 2'].fillna('None', inplace = True)\n",
    "df['BsmtFin Type 1'].fillna('None', inplace = True)\n",
    "df['Bsmt Cond'].fillna('None', inplace = True)\n",
    "df['Bsmt Qual'].fillna('None', inplace = True)\n",
    "df['Mas Vnr Type'].fillna('None', inplace = True)\n",
    "df['Garage Yr Blt'].fillna('None', inplace = True)\n",
    "\n",
    "\n",
    "df['Garage Cars'].fillna(0, inplace=True)\n",
    "df['Garage Area'].fillna(0, inplace=True)\n",
    "df['Total Bsmt SF'].fillna(0, inplace = True)\n",
    "df['BsmtFin SF 1'].fillna(0, inplace = True)\n",
    "df['Bsmt Full Bath'].fillna(0, inplace = True)\n",
    "df['Bsmt Unf SF'].fillna(0, inplace = True)\n",
    "df['Bsmt Half Bath'].fillna(0, inplace = True)\n",
    "df['Mas Vnr Area'].fillna(0, inplace = True)\n",
    "df['BsmtFin SF 2'].fillna(0, inplace = True)\n",
    "\n",
    "df.drop(['Pool QC','Misc Feature','Alley','Fence','Fireplace Qu'], axis = 1, inplace = True)\n",
    "\n",
    "submit['Mas Vnr Area'].fillna(0, inplace = True)\n",
    "\n",
    "#Dropping and cleaning a variety of test predictors,  many of these were used during my modeling stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning I determined my features.  The first step to this was splitting them into numerical and categorical values.  This was important because I often ran transformative functions on the numerical data before my categorical ones.  Later, I would dummy out my categorical columns to produce binary values corresponding to the individual categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "numeric = df._get_numeric_data()\n",
    "num_cols = df._get_numeric_data().drop(['Id','PID'], axis = 1).columns\n",
    "num_cols.shape\n",
    "\n",
    "categorical = df.select_dtypes(exclude=[\"number\",\"bool_\"]).columns\n",
    "\n",
    "numeric_sub = submit._get_numeric_data\n",
    "num_cols_sub = submit._get_numeric_data().columns\n",
    "\n",
    "#Numeric and Categorical columns for a general test including nearly all predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= num_cols_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df[categorical])\n",
    "\n",
    "#Dummies created from categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies.corrwith(df['SalePrice']).sort_values(ascending = False)\n",
    "#Corr_test = dummies.drop(features,axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_features = ['Foundation_PConc','BsmtFin Type 1_GLQ','Neighborhood_NridgHt',\n",
    "         'Exter Qual_Gd','Bsmt Exposure_Gd','Sale Type_New','Garage Type_Attchd','Exterior 1st_VinylSd',\n",
    "         'Exterior 2nd_VinylSd','Mas Vnr Type_Stone','Kitchen Qual_Gd','Paved Drive_Y','Central Air_Y','Garage Cond_TA',\n",
    "         'Roof Style_Hip','Neighborhood_NoRidge','Mas Vnr Type_BrkFace','Neighborhood_StoneBr','Electrical_SBrkr',\n",
    "                'MS Zoning_RM','Bsmt Exposure_No','Lot Shape_Reg','Heating QC_TA','Foundation_CBlock',\n",
    "                'Garage Type_Detchd','Mas Vnr Type_None','Garage Finish_Unf','Bsmt Qual_TA','Kitchen Qual_TA','Exter Qual_TA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corrwith(df['SalePrice'])\n",
    "\n",
    "#Determining highest positive and negative correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_df_corr = df_corr.sort_values(ascending = False)\n",
    "\n",
    "#sorted_df_corr\n",
    "\n",
    "#Sorted Corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearch from previous test\n",
    "\n",
    "#grid_params = {\n",
    " #   ]\n",
    "#}\n",
    "#gs = GridSearchCV(\n",
    "  #  LinearRegression(),\n",
    " #   grid_params,)\n",
    "\n",
    "#gs_results = gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining my X and Y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tbaca\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "X = df[features]\n",
    "X.drop(['Garage Yr Blt'], axis = 1, inplace = True)\n",
    "X_submit = submit[features]\n",
    "X_submit.drop(['Garage Yr Blt'], axis = 1, inplace = True)\n",
    "y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included many of the steps I took during my testing phases.  While many of these worked in theory they often did not produce a score better than the simplest linear model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polyfeatures\n",
    "\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#pf = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "#pf = pf.fit(X)\n",
    "#X = pf.transform(X)\n",
    "\n",
    "#X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polyfeatures\n",
    "\n",
    "#pf = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "#pf = pf.fit(X_submit)\n",
    "#X_submit = pf.transform(X_submit)\n",
    "\n",
    "#X_submit = pd.DataFrame(X_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df,columns =categorical,drop_first = True)\n",
    "submit_dummies = pd.get_dummies(submit,columns =categorical, drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from previous tests\n",
    "\n",
    "\n",
    "#X[['Overall Qual_2','Overall Qual_3',\n",
    "             # 'Overall Qual_4','Overall Qual_5','Overall Qual_6',\n",
    "              #'Overall Qual_7','Overall Qual_8','Overall Qual_9','Overall Qual_10']] = df[['Overall Qual_2','Overall Qual_3',\n",
    "              #'Overall Qual_4','Overall Qual_5','Overall Qual_6',\n",
    "              #'Overall Qual_7','Overall Qual_8','Overall Qual_9','Overall Qual_10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from pevious tests\n",
    "\n",
    "\n",
    "#X_submit[['Overall Qual_2','Overall Qual_3',\n",
    "              #'Overall Qual_4','Overall Qual_5','Overall Qual_6',\n",
    "              #'Overall Qual_7','Overall Qual_8','Overall Qual_9','Overall Qual_10']] = submit[['Overall Qual_2','Overall Qual_3',\n",
    "              #'Overall Qual_4','Overall Qual_5','Overall Qual_6',\n",
    "              #'Overall Qual_7','Overall Qual_8','Overall Qual_9','Overall Qual_10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2051, 37)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_dummies_final = submit_dummies[dummies_features]\n",
    "dummies_final = dummies[dummies_features]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit=pd.concat([X_submit,submit_dummies_final],axis = 1)\n",
    "X=pd.concat([X,dummies_final],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I concatenate the two data types into one X, on both the training and test data.  Thisway we can fit, score and predict on our test set.  For validation purposes I train test split, splitting my test set into 2 an allowing me to cross validate my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Lot Frontage', axis = 1)\n",
    "X_submit = X_submit.drop('Lot Frontage', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_scaled = ss.fit_transform(X_train)\n",
    "#X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        int64\n",
       "PID                       int64\n",
       "MS SubClass               int64\n",
       "Lot Area                  int64\n",
       "Overall Qual              int64\n",
       "Overall Cond              int64\n",
       "Year Built                int64\n",
       "Year Remod/Add            int64\n",
       "Mas Vnr Area            float64\n",
       "BsmtFin SF 1            float64\n",
       "BsmtFin SF 2            float64\n",
       "Bsmt Unf SF             float64\n",
       "Total Bsmt SF           float64\n",
       "1st Flr SF                int64\n",
       "2nd Flr SF                int64\n",
       "Low Qual Fin SF           int64\n",
       "Gr Liv Area               int64\n",
       "Bsmt Full Bath          float64\n",
       "Bsmt Half Bath          float64\n",
       "Full Bath                 int64\n",
       "Half Bath                 int64\n",
       "Bedroom AbvGr             int64\n",
       "Kitchen AbvGr             int64\n",
       "TotRms AbvGrd             int64\n",
       "Fireplaces                int64\n",
       "Garage Cars             float64\n",
       "Garage Area             float64\n",
       "Wood Deck SF              int64\n",
       "Open Porch SF             int64\n",
       "Enclosed Porch            int64\n",
       "                         ...   \n",
       "Foundation_PConc          uint8\n",
       "BsmtFin Type 1_GLQ        uint8\n",
       "Neighborhood_NridgHt      uint8\n",
       "Exter Qual_Gd             uint8\n",
       "Bsmt Exposure_Gd          uint8\n",
       "Sale Type_New             uint8\n",
       "Garage Type_Attchd        uint8\n",
       "Exterior 1st_VinylSd      uint8\n",
       "Exterior 2nd_VinylSd      uint8\n",
       "Mas Vnr Type_Stone        uint8\n",
       "Kitchen Qual_Gd           uint8\n",
       "Paved Drive_Y             uint8\n",
       "Central Air_Y             uint8\n",
       "Garage Cond_TA            uint8\n",
       "Roof Style_Hip            uint8\n",
       "Neighborhood_NoRidge      uint8\n",
       "Mas Vnr Type_BrkFace      uint8\n",
       "Neighborhood_StoneBr      uint8\n",
       "Electrical_SBrkr          uint8\n",
       "MS Zoning_RM              uint8\n",
       "Bsmt Exposure_No          uint8\n",
       "Lot Shape_Reg             uint8\n",
       "Heating QC_TA             uint8\n",
       "Foundation_CBlock         uint8\n",
       "Garage Type_Detchd        uint8\n",
       "Mas Vnr Type_None         uint8\n",
       "Garage Finish_Unf         uint8\n",
       "Bsmt Qual_TA              uint8\n",
       "Kitchen Qual_TA           uint8\n",
       "Exter Qual_TA             uint8\n",
       "Length: 66, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling and Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fit my model with my train and test sets to score them accordingly.  After I found a satisfactory score between my train and test sets I would go and fit my model with the entire dataset.  I found that fitting my model with only the X_train it would yield a worse prediction score.  I presumed this was due to only using 50% of the potential data for predictions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model = lm.fit(X_train,y_train)\n",
    "\n",
    "predictions  =  model.predict(X_submit)\n",
    "score        =  model.score(X_train,y_train)\n",
    "betacoef     =  model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887215446212806"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "model = lm.fit(X_train,y_train)\n",
    "\n",
    "predictions  =  model.predict(X_submit)\n",
    "score        =  model.score(X_test,y_test)\n",
    "betacoef     =  model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8377974650651789"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying my predictions to the test set and creating my Submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_submit_scaled=ss.fit_transform(X_submit)\n",
    "\n",
    "submit['SalePrice'] = predictions\n",
    "\n",
    "\n",
    "\n",
    "submission10 = submit[['Id','SalePrice']]\n",
    "\n",
    "submission10.to_csv(\"Submission10.csv\")\n",
    "\n",
    "#Submission process"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
